
=============
== PyTorch ==
=============

NVIDIA Release 20.08 (build 15516749)
PyTorch Version 1.7.0a0+8deb4fe

Container image Copyright (c) 2020, NVIDIA CORPORATION.  All rights reserved.

Copyright (c) 2014-2020 Facebook Inc.
Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)
Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)
Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)
Copyright (c) 2011-2013 NYU                      (Clement Farabet)
Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)
Copyright (c) 2006      Idiap Research Institute (Samy Bengio)
Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)
Copyright (c) 2015      Google Inc.
Copyright (c) 2015      Yangqing Jia
Copyright (c) 2013-2016 The Caffe contributors
All rights reserved.

Various files include modifications (c) NVIDIA CORPORATION.  All rights reserved.
NVIDIA modifications are covered by the license terms that apply to the underlying project or file.

NOTE: MOFED driver for multi-node communication was not detected.
      Multi-node communication performance may be reduced.

NOTE: The SHMEM allocation limit is set to the default of 64MB.  This may be
   insufficient for PyTorch.  NVIDIA recommends the use of the following flags:
   nvidia-docker run --ipc=host ...


Please cite the following paper when using nnUNet:
Fabian Isensee, Paul F. JÃ¤ger, Simon A. A. Kohl, Jens Petersen, Klaus H. Maier-Hein "Automated Design of Deep Learning Methods for Biomedical Image Segmentation" arXiv preprint arXiv:1904.08128 (2020).
If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet

nnUNet_raw_data_base is not defined and nnU-Net can only be used on data for which preprocessed files are already present on your system. nnU-Net cannot be used for experiment planning and preprocessing like this. If this is not intended, please read nnunet/paths.md for information on how to set this up properly.
nnUNet_preprocessed is not defined and nnU-Net can not be used for preprocessing or training. If this is not intended, please read nnunet/pathy.md for information on how to set this up.
RESULTS_FOLDER is not defined and nnU-Net cannot be used for training or inference. If this is not intended behavior, please read nnunet/paths.md for information on how to set this up
This Docker is meant to reproduce the test set results submitted by Fabian Isensee et al. to the BraTS 2020 challenge. This is Version 1.0
Found 1 case identifiers! Here are some examples: pat
emptying cuda cache
loading parameters for folds, (0, 1, 2, 3, 4)
using the following model files:  ['/params/nnUNetTrainerV2BraTSRegions_DA3_BN_BD__nnUNetPlansv2.1_bs5/fold_0/model_final_checkpoint.model', '/params/nnUNetTrainerV2BraTSRegions_DA3_BN_BD__nnUNetPlansv2.1_bs5/fold_1/model_final_checkpoint.model', '/params/nnUNetTrainerV2BraTSRegions_DA3_BN_BD__nnUNetPlansv2.1_bs5/fold_2/model_final_checkpoint.model', '/params/nnUNetTrainerV2BraTSRegions_DA3_BN_BD__nnUNetPlansv2.1_bs5/fold_3/model_final_checkpoint.model', '/params/nnUNetTrainerV2BraTSRegions_DA3_BN_BD__nnUNetPlansv2.1_bs5/fold_4/model_final_checkpoint.model']
starting preprocessing generator
starting prediction...
preprocessing /app/data/results/nnUNetTrainerV2BraTSRegions_DA3_BN_BD__nnUNetPlansv2.1_bs5/tumor_isen2020_class.nii.gz
using preprocessor GenericPreprocessor
before crop: (4, 155, 240, 240) after crop: (4, 143, 166, 134) spacing: [1. 1. 1.] 

no resampling necessary
no resampling necessary
before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (4, 143, 166, 134)} 
after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (4, 143, 166, 134)} 

(4, 143, 166, 134)
This worker has ended successfully, no errors to report
predicting /app/data/results/nnUNetTrainerV2BraTSRegions_DA3_BN_BD__nnUNetPlansv2.1_bs5/tumor_isen2020_class.nii.gz
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (4, 143, 166, 134)
patch size: [128 128 128]
steps (x, y, and z): [[0, 15], [0, 38], [0, 6]]
number of tiles: 8
computing Gaussian
prediction done
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (4, 143, 166, 134)
patch size: [128 128 128]
steps (x, y, and z): [[0, 15], [0, 38], [0, 6]]
number of tiles: 8
using precomputed Gaussian
prediction done
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (4, 143, 166, 134)
patch size: [128 128 128]
steps (x, y, and z): [[0, 15], [0, 38], [0, 6]]
number of tiles: 8
using precomputed Gaussian
prediction done
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (4, 143, 166, 134)
patch size: [128 128 128]
steps (x, y, and z): [[0, 15], [0, 38], [0, 6]]
number of tiles: 8
using precomputed Gaussian
prediction done
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (4, 143, 166, 134)
patch size: [128 128 128]
steps (x, y, and z): [[0, 15], [0, 38], [0, 6]]
number of tiles: 8
using precomputed Gaussian
prediction done
inference done. Now waiting for the segmentation export to finish...
force_separate_z: None interpolation order: 1
no resampling necessary
WARNING! Cannot run postprocessing because the postprocessing file is missing. Make sure to run consolidate_folds in the output folder of the model first!
The folder you need to run this in is /params/nnUNetTrainerV2BraTSRegions_DA3_BN_BD__nnUNetPlansv2.1_bs5
emptying cuda cache
loading parameters for folds, (0, 1, 2, 3, 4)
using the following model files:  ['/params/nnUNetTrainerV2BraTSRegions_DA4_BN_BD__nnUNetPlansv2.1_bs5/fold_0/model_final_checkpoint.model', '/params/nnUNetTrainerV2BraTSRegions_DA4_BN_BD__nnUNetPlansv2.1_bs5/fold_1/model_final_checkpoint.model', '/params/nnUNetTrainerV2BraTSRegions_DA4_BN_BD__nnUNetPlansv2.1_bs5/fold_2/model_final_checkpoint.model', '/params/nnUNetTrainerV2BraTSRegions_DA4_BN_BD__nnUNetPlansv2.1_bs5/fold_3/model_final_checkpoint.model', '/params/nnUNetTrainerV2BraTSRegions_DA4_BN_BD__nnUNetPlansv2.1_bs5/fold_4/model_final_checkpoint.model']
starting preprocessing generator
starting prediction...
preprocessing /app/data/results/nnUNetTrainerV2BraTSRegions_DA4_BN_BD__nnUNetPlansv2.1_bs5/tumor_isen2020_class.nii.gz
using preprocessor GenericPreprocessor
before crop: (4, 155, 240, 240) after crop: (4, 143, 166, 134) spacing: [1. 1. 1.] 

no resampling necessary
no resampling necessary
before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (4, 143, 166, 134)} 
after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (4, 143, 166, 134)} 

(4, 143, 166, 134)
This worker has ended successfully, no errors to report
predicting /app/data/results/nnUNetTrainerV2BraTSRegions_DA4_BN_BD__nnUNetPlansv2.1_bs5/tumor_isen2020_class.nii.gz
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (4, 143, 166, 134)
patch size: [128 128 128]
steps (x, y, and z): [[0, 15], [0, 38], [0, 6]]
number of tiles: 8
computing Gaussian
prediction done
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (4, 143, 166, 134)
patch size: [128 128 128]
steps (x, y, and z): [[0, 15], [0, 38], [0, 6]]
number of tiles: 8
using precomputed Gaussian
prediction done
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (4, 143, 166, 134)
patch size: [128 128 128]
steps (x, y, and z): [[0, 15], [0, 38], [0, 6]]
number of tiles: 8
using precomputed Gaussian
prediction done
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (4, 143, 166, 134)
patch size: [128 128 128]
steps (x, y, and z): [[0, 15], [0, 38], [0, 6]]
number of tiles: 8
using precomputed Gaussian
prediction done
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (4, 143, 166, 134)
patch size: [128 128 128]
steps (x, y, and z): [[0, 15], [0, 38], [0, 6]]
number of tiles: 8
using precomputed Gaussian
prediction done
inference done. Now waiting for the segmentation export to finish...
force_separate_z: None interpolation order: 1
no resampling necessary
WARNING! Cannot run postprocessing because the postprocessing file is missing. Make sure to run consolidate_folds in the output folder of the model first!
The folder you need to run this in is /params/nnUNetTrainerV2BraTSRegions_DA4_BN_BD__nnUNetPlansv2.1_bs5
emptying cuda cache
loading parameters for folds, (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14)
using the following model files:  ['/params/nnUNetTrainerV2BraTSRegions_DA4_BN__nnUNetPlansv2.1_bs5/fold_0/model_final_checkpoint.model', '/params/nnUNetTrainerV2BraTSRegions_DA4_BN__nnUNetPlansv2.1_bs5/fold_1/model_final_checkpoint.model', '/params/nnUNetTrainerV2BraTSRegions_DA4_BN__nnUNetPlansv2.1_bs5/fold_2/model_final_checkpoint.model', '/params/nnUNetTrainerV2BraTSRegions_DA4_BN__nnUNetPlansv2.1_bs5/fold_3/model_final_checkpoint.model', '/params/nnUNetTrainerV2BraTSRegions_DA4_BN__nnUNetPlansv2.1_bs5/fold_4/model_final_checkpoint.model', '/params/nnUNetTrainerV2BraTSRegions_DA4_BN__nnUNetPlansv2.1_bs5/fold_5/model_final_checkpoint.model', '/params/nnUNetTrainerV2BraTSRegions_DA4_BN__nnUNetPlansv2.1_bs5/fold_6/model_final_checkpoint.model', '/params/nnUNetTrainerV2BraTSRegions_DA4_BN__nnUNetPlansv2.1_bs5/fold_7/model_final_checkpoint.model', '/params/nnUNetTrainerV2BraTSRegions_DA4_BN__nnUNetPlansv2.1_bs5/fold_8/model_final_checkpoint.model', '/params/nnUNetTrainerV2BraTSRegions_DA4_BN__nnUNetPlansv2.1_bs5/fold_9/model_final_checkpoint.model', '/params/nnUNetTrainerV2BraTSRegions_DA4_BN__nnUNetPlansv2.1_bs5/fold_10/model_final_checkpoint.model', '/params/nnUNetTrainerV2BraTSRegions_DA4_BN__nnUNetPlansv2.1_bs5/fold_11/model_final_checkpoint.model', '/params/nnUNetTrainerV2BraTSRegions_DA4_BN__nnUNetPlansv2.1_bs5/fold_12/model_final_checkpoint.model', '/params/nnUNetTrainerV2BraTSRegions_DA4_BN__nnUNetPlansv2.1_bs5/fold_13/model_final_checkpoint.model', '/params/nnUNetTrainerV2BraTSRegions_DA4_BN__nnUNetPlansv2.1_bs5/fold_14/model_final_checkpoint.model']
starting preprocessing generator
starting prediction...
preprocessing /app/data/results/nnUNetTrainerV2BraTSRegions_DA4_BN__nnUNetPlansv2.1_bs5/tumor_isen2020_class.nii.gz
using preprocessor GenericPreprocessor
before crop: (4, 155, 240, 240) after crop: (4, 143, 166, 134) spacing: [1. 1. 1.] 

no resampling necessary
no resampling necessary
before: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (4, 143, 166, 134)} 
after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (4, 143, 166, 134)} 

(4, 143, 166, 134)
This worker has ended successfully, no errors to report
predicting /app/data/results/nnUNetTrainerV2BraTSRegions_DA4_BN__nnUNetPlansv2.1_bs5/tumor_isen2020_class.nii.gz
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (4, 143, 166, 134)
patch size: [128 128 128]
steps (x, y, and z): [[0, 15], [0, 38], [0, 6]]
number of tiles: 8
computing Gaussian
prediction done
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (4, 143, 166, 134)
patch size: [128 128 128]
steps (x, y, and z): [[0, 15], [0, 38], [0, 6]]
number of tiles: 8
using precomputed Gaussian
prediction done
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (4, 143, 166, 134)
patch size: [128 128 128]
steps (x, y, and z): [[0, 15], [0, 38], [0, 6]]
number of tiles: 8
using precomputed Gaussian
prediction done
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (4, 143, 166, 134)
patch size: [128 128 128]
steps (x, y, and z): [[0, 15], [0, 38], [0, 6]]
number of tiles: 8
using precomputed Gaussian
prediction done
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (4, 143, 166, 134)
patch size: [128 128 128]
steps (x, y, and z): [[0, 15], [0, 38], [0, 6]]
number of tiles: 8
using precomputed Gaussian
prediction done
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (4, 143, 166, 134)
patch size: [128 128 128]
steps (x, y, and z): [[0, 15], [0, 38], [0, 6]]
number of tiles: 8
using precomputed Gaussian
prediction done
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (4, 143, 166, 134)
patch size: [128 128 128]
steps (x, y, and z): [[0, 15], [0, 38], [0, 6]]
number of tiles: 8
using precomputed Gaussian
prediction done
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (4, 143, 166, 134)
patch size: [128 128 128]
steps (x, y, and z): [[0, 15], [0, 38], [0, 6]]
number of tiles: 8
using precomputed Gaussian
prediction done
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (4, 143, 166, 134)
patch size: [128 128 128]
steps (x, y, and z): [[0, 15], [0, 38], [0, 6]]
number of tiles: 8
using precomputed Gaussian
prediction done
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (4, 143, 166, 134)
patch size: [128 128 128]
steps (x, y, and z): [[0, 15], [0, 38], [0, 6]]
number of tiles: 8
using precomputed Gaussian
prediction done
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (4, 143, 166, 134)
patch size: [128 128 128]
steps (x, y, and z): [[0, 15], [0, 38], [0, 6]]
number of tiles: 8
using precomputed Gaussian
prediction done
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (4, 143, 166, 134)
patch size: [128 128 128]
steps (x, y, and z): [[0, 15], [0, 38], [0, 6]]
number of tiles: 8
using precomputed Gaussian
prediction done
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (4, 143, 166, 134)
patch size: [128 128 128]
steps (x, y, and z): [[0, 15], [0, 38], [0, 6]]
number of tiles: 8
using precomputed Gaussian
prediction done
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (4, 143, 166, 134)
patch size: [128 128 128]
steps (x, y, and z): [[0, 15], [0, 38], [0, 6]]
number of tiles: 8
using precomputed Gaussian
prediction done
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (4, 143, 166, 134)
patch size: [128 128 128]
steps (x, y, and z): [[0, 15], [0, 38], [0, 6]]
number of tiles: 8
using precomputed Gaussian
prediction done
inference done. Now waiting for the segmentation export to finish...
force_separate_z: None interpolation order: 1
no resampling necessary
WARNING! Cannot run postprocessing because the postprocessing file is missing. Make sure to run consolidate_folds in the output folder of the model first!
The folder you need to run this in is /params/nnUNetTrainerV2BraTSRegions_DA4_BN__nnUNetPlansv2.1_bs5
force_separate_z: None interpolation order: 3
no resampling necessary
